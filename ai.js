const OpenAI = require("openai");
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Prompt Base (PEI V1)
function construirPrompt(historico, sessao) {
  const intro = `
Voc√™ √© o PEI (Porta de Entrada Inteligente), um assistente de recep√ß√£o da BRYNIX.

üß† Sua miss√£o √© recepcionar visitantes do site com leveza, intelig√™ncia e simpatia ‚Äî conduzindo uma conversa fluida, humana e profissional.

üéØ Seu objetivo principal √© descobrir de forma natural e progressiva (nunca tudo de uma vez):
- Nome da pessoa
- Nome da empresa
- Forma de contato (WhatsApp ou e-mail)
- O desafio ou objetivo principal da pessoa
- Porte da empresa (micro, pequena, m√©dia, grande)
- Se est√° apenas conhecendo ou realmente interessado agora

‚ö†Ô∏è Importante:
- **Nunca reinicie a conversa**.
- **Nunca repita perguntas j√° respondidas**.
- Sempre considere tudo que foi dito antes.
- Seja natural, traga varia√ß√µes nas frases e conduza como quem est√° ouvindo de verdade.

‚ú® Estilo de fala:
- Profissional, sem ser fria
- Acolhedora, sem parecer rob√≥tica
- Curiosa, sem ser invasiva
- Fluida, como um humano real

Exemplos de abordagem:

Usu√°rio: Ol√°, sou a Bruna.
PEI: Oi, Bruna! üòä Que bom ter voc√™ por aqui. Me conta: com o que voc√™ trabalha?

Usu√°rio: Tenho um restaurante.
PEI: Que del√≠cia! üçΩÔ∏è E como se chama seu restaurante?

Usu√°rio: Chama Esta√ß√£o Sabor.
PEI: Nome √≥timo! J√° me deu fome s√≥ de ouvir üòÑ Me conta uma coisa: o que mais tem tirado seu sono por a√≠? Talvez eu possa ajudar.

‚Üí Continue nesse estilo. N√£o interrompa bruscamente. Use o que o usu√°rio fala para aprofundar.
`;

  const historicoTexto = historico
    .map(msg => `${msg.de === "usuario" ? "Usu√°rio" : "PEI"}: ${msg.texto}`)
    .join("\n");

  return `${intro}\n\n${historicoTexto}\n\nPEI:`;
}

// RegEx para extra√ß√£o de dados
function extrairDados(resposta) {
  const coleta = {};

  const regexes = {
    nome: /(?:meu nome (?:√©|sou|chamo-me)|sou o|sou a)\s+([A-Z√Ä-√ö][a-z√†-√∫]+(?:\s[A-Z√Ä-√ö][a-z√†-√∫]+)*)/i,
    empresa: /(?:minha empresa|empresa (?:chama-se|se chama|√©|nome √©))[:\-]?\s*([A-Z0-9&.\- ]{3,})/i,
    contato: /(\(?\d{2}\)?\s?\d{4,5}[-\s]?\d{4})|([a-z0-9_.+-]+@[a-z0-9-]+\.[a-z.]+)/i,
    porte: /\b(micro|pequena|m√©dia|grande)\b/i,
    desafio: /(desafio|problema|dificuldade|quest√£o)[^.!?]{5,}/i,
    classificacao: /\b(quente|morno|frio)\b/i
  };

  for (const campo in regexes) {
    const match = resposta.match(regexes[campo]);
    if (match) {
      coleta[campo] = match[1] || match[2];
    }
  }

  return coleta;
}

// Fun√ß√£o principal da IA
async function gerarResposta(mensagem, sessao = {}) {
  try {
    // Garante estrutura da sess√£o
    if (typeof sessao !== 'object' || sessao === null) sessao = {};
    if (!Array.isArray(sessao.historico)) sessao.historico = [];
    if (typeof sessao.coletado !== 'object' || sessao.coletado === null) sessao.coletado = {};

    // Atualiza hist√≥rico com a nova entrada do usu√°rio
    sessao.historico.push({ de: "usuario", texto: mensagem });

    // Gera√ß√£o do prompt contextualizado
    const prompt = construirPrompt(sessao.historico, sessao);

    const completion = await openai.chat.completions.create({
      model: "gpt-4o", // ou "gpt-3.5-turbo"
      messages: [
        { role: "system", content: prompt },
        { role: "user", content: mensagem }
      ],
      temperature: 0.7,
      max_tokens: 500,
    });

    const resposta = completion.choices[0].message.content.trim();

    // Atualiza hist√≥rico com a resposta do PEI
    sessao.historico.push({ de: "bot", texto: resposta });

    // Extrai dados da intera√ß√£o
    const dadosExtraidos = extrairDados(`${mensagem}\n${resposta}`);

    // Atualiza sess√£o com novos dados, sem sobrescrever os anteriores
    for (const chave in dadosExtraidos) {
      if (!sessao.coletado[chave]) {
        sessao.coletado[chave] = dadosExtraidos[chave];
      }
    }

    console.log("üí° Dados coletados at√© agora:", sessao.coletado);

    return { resposta, coleta: sessao.coletado };
  } catch (erro) {
    console.error("‚ùå Erro em gerarResposta:", erro.message);
    return {
      resposta: "Desculpe, houve um erro ao gerar a resposta. Pode tentar novamente?",
      coleta: (sessao && sessao.coletado) ? sessao.coletado : {},
    };
  }
}

module.exports = gerarResposta;
