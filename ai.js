const OpenAI = require("openai");

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function gerarResposta(mensagem, sessao) {
  // Recupera hist√≥rico e coleta persistida
  const historicoFormatado = sessao.historico?.map(m => ({
    role: m.de === "usuario" ? "user" : "assistant",
    content: m.texto
  })) || [];

  const coletaAnterior = sessao.coleta || {};
  const nome = coletaAnterior.nome;
  const saudacao = nome ? `Ol√°, ${nome}!` : `Ol√°!`;

  // Adiciona uma sauda√ß√£o inicial se for a primeira intera√ß√£o
  if (historicoFormatado.length === 0) {
    historicoFormatado.unshift({
      role: "assistant",
      content: "Ol√°! Eu sou a ALICE, Analista de Automa√ß√£o da BRYNIX. Como posso ajudar voc√™ com IA nos neg√≥cios?"
    });
  }

  // Constr√≥i o prompt com contexto
  const prompt = [
    {
      role: "system",
      content: `
Voc√™ √© a ALICE ‚Äî Analista de Neg√≥cios e Automa√ß√£o da BRYNIX.

Fale com empatia, como um consultor experiente em IA, sempre com foco em neg√≥cios reais.

üö® ATEN√á√ÉO: Voc√™ est√° dando continuidade a uma conversa, e o visitante j√° informou os seguintes dados (caso existam):

${JSON.stringify(coletaAnterior, null, 2)}

NUNCA repita perguntas j√° feitas.
Sempre use o nome do visitante se ele j√° foi coletado.
Mantenha uma conversa fluida, progressiva e natural.

üéØ Objetivos:
1. Ajudar com d√∫vidas sobre uso de IA nos neg√≥cios.
2. Coletar as seguintes informa√ß√µes (se ainda faltarem):
  - nome
  - empresa
  - contato
  - desafio
  - classificacao (quente, morno, frio)

üî• Classifica√ß√£o:
- **quente**: dor clara + interesse real ou urg√™ncia/or√ßamento
- **morno**: tem interesse, mas ainda sem timing ou verba clara
- **frio**: curioso, explorando, sem inten√ß√£o aparente

üß† Exemplo de resposta esperada:
{
  "resposta": "<mensagem ao usu√°rio>",
  "coleta": {
    "nome": "...",
    "empresa": "...",
    "contato": "...",
    "desafio": "...",
    "classificacao": "quente|morno|frio"
  }
}
`.trim()
    },
    ...historicoFormatado,
    { role: "user", content: mensagem }
  ];

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4",
      messages: prompt,
      temperature: 0.6,
      max_tokens: 1000,
    });

    const jsonBruto = completion.choices[0].message.content;

    const json = JSON.parse(jsonBruto);

    return {
      resposta: json.resposta,
      coleta: json.coleta || {}
    };
  } catch (e) {
    console.error("Erro ao interpretar resposta da IA:", e);
    return { resposta: "Desculpe, algo deu errado aqui. Pode repetir?", coleta: {} };
  }
}

module.exports = gerarResposta;
