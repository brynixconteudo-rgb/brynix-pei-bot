const OpenAI = require("openai");
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// üéØ Prompt base para modo guiado (structured)
const promptBaseGuiado = `
Voc√™ √© o PEI (Porta de Entrada Inteligente), um assistente de recep√ß√£o da BRYNIX.

üß† Sua miss√£o √© recepcionar visitantes do site com leveza, intelig√™ncia e simpatia ‚Äî conduzindo uma conversa fluida, humana e profissional.

üéØ Seu objetivo principal √© descobrir de forma natural e progressiva (nunca tudo de uma vez):
- Nome da pessoa
- Nome da empresa
- Setor
- Forma de contato (WhatsApp ou e-mail)
- O desafio ou objetivo principal da pessoa
- Porte da empresa (micro, pequena, m√©dia, grande)
- Se est√° apenas conhecendo ou realmente interessado agora

‚ö†Ô∏è Importante:
- Nunca reinicie a conversa.
- Nunca repita perguntas j√° respondidas.
- Sempre considere tudo que foi dito antes.
- Seja natural, traga varia√ß√µes nas frases e conduza como quem est√° ouvindo de verdade.

‚ú® Estilo de fala:
- Profissional, sem ser fria
- Acolhedora, sem parecer rob√≥tica
- Curiosa, sem ser invasiva
- Fluida, como um humano real
`;

// üìå Campos obrigat√≥rios
const camposEsperados = ["nome", "empresa", "setor", "contato", "desafio", "porte", "classificacao"];

// üîç Regex inteligente
function extrairDados(texto) {
  const coleta = {};
  const regexes = {
    nome: /(?:meu nome √©|me chamo|sou o|sou a|sou)\s+([A-Z√Ä-√ö][a-z√†-√∫]+(?:\s[A-Z√Ä-√ö][a-z√†-√∫]+)?)/i,
    empresa: /(?:minha empresa|empresa (?:chama-se|se chama|√©|nome √©)|sou (?:da|do|de)\s+(?:loja|empresa)?\s*|trabalho (?:na|no|em)\s+)([A-Z0-9&.\- ]{3,})/i,
    setor: /(?:setor|segmento|atuo no|trabalho com)\s+([a-z√†-√∫\s]+)/i,
    contato: /(\(?\d{2}\)?\s?\d{4,5}[-\s]?\d{4})|([a-z0-9_.+-]+@[a-z0-9-]+\.[a-z.]+)/i,
    porte: /\b(micro|pequena|m√©dia|grande)\b/i,
    desafio: /(?:desafio|problema|dificuldade|quest√£o|objetivo|estou buscando|quero|preciso|gostaria de)[^.!?\n]{10,}/i,
    classificacao: /\b(quente|morno|frio)\b/i,
  };

  for (const campo in regexes) {
    const match = texto.match(regexes[campo]);
    if (match) {
      coleta[campo] = match[1] || match[0];
    }
  }

  return coleta;
}

// üìç Modo guiado (estruturado)
async function gerarRespostaEstruturada(mensagem, sessao = {}) {
  try {
    if (typeof sessao !== "object") sessao = {};
    if (!Array.isArray(sessao.historico)) sessao.historico = [];
    if (typeof sessao.coletado !== "object") sessao.coletado = {};

    sessao.historico.push({ de: "usuario", texto: mensagem });

    const pendentes = camposEsperados.filter(campo => !sessao.coletado[campo]);
    let promptExtra = "";

    if (pendentes.length > 0) {
      promptExtra = `Ainda faltam as seguintes informa√ß√µes: ${pendentes.join(", ")}. Conduza de forma natural para obt√™-las.`;
    } else {
      promptExtra = "‚úÖ Todos os dados foram coletados. Finalize com simpatia e diga que a BRYNIX entrar√° em contato.";
    }

    const mensagens = [
      { role: "system", content: `${promptBaseGuiado}\n\n${promptExtra}` },
      ...sessao.historico.map(msg => ({
        role: msg.de === "usuario" ? "user" : "assistant",
        content: msg.texto,
      }))
    ];

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: mensagens,
      temperature: 0.7,
      max_tokens: 500,
    });

    const resposta = completion.choices[0].message.content.trim();
    sessao.historico.push({ de: "bot", texto: resposta });

    // An√°lise de coleta
    const historicoCompleto = sessao.historico.map(h => h.texto).join("\n");
    const dadosExtraidos = extrairDados(historicoCompleto);

    for (const chave in dadosExtraidos) {
      if (!sessao.coletado[chave]) {
        sessao.coletado[chave] = dadosExtraidos[chave];
      }
    }

    const completo = camposEsperados.every(c => sessao.coletado[c]);

    if (completo && !sessao.coletado.encerrado) {
      sessao.coletado.encerrado = true;
      const fechamento = `Perfeito! üòä Com todas essas informa√ß√µes, j√° posso passar seu contato para nosso time.

A equipe da BRYNIX vai falar com voc√™ em breve para entender melhor o seu cen√°rio e te mostrar como nossas solu√ß√µes de IA podem gerar valor real para o seu neg√≥cio.

Obrigado por compartilhar tudo com a gente. Foi √≥timo conversar com voc√™! üëã`;

      return {
        resposta: fechamento,
        coleta: sessao.coletado
      };
    }

    return {
      resposta,
      coleta: sessao.coletado,
    };
  } catch (erro) {
    console.error("‚ùå Erro em gerarRespostaEstruturada:", erro.message);
    return {
      resposta: "Desculpe, houve um erro ao gerar a resposta.",
      coleta: sessao.coletado || {},
    };
  }
}

// üìç Modo livre (sem coleta)
async function gerarRespostaLivre(mensagem, historico = []) {
  try {
    const mensagens = [
      { role: "system", content: `
Voc√™ √© o PEI, o assistente de recep√ß√£o da BRYNIX.

Converse com o visitante de forma fluida, acolhedora e inteligente. Responda d√∫vidas sobre IA, automa√ß√£o, neg√≥cios e a atua√ß√£o da BRYNIX. Mantenha o foco em ajudar o visitante com sua curiosidade ou interesse, sem se perder em digress√µes.

N√£o colete dados pessoais. Seja natural e prestativo.` },
      ...historico.map(msg => ({
        role: msg.de === "usuario" ? "user" : "assistant",
        content: msg.texto,
      })),
      { role: "user", content: mensagem }
    ];

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: mensagens,
      temperature: 0.7,
      max_tokens: 400,
    });

    return {
      resposta: completion.choices[0].message.content.trim(),
      coleta: {}
    };
  } catch (erro) {
    console.error("‚ùå Erro em gerarRespostaLivre:", erro.message);
    return {
      resposta: "Desculpe, algo saiu errado. Tente de novo.",
      coleta: {}
    };
  }
}

module.exports = {
  gerarRespostaEstruturada,
  gerarRespostaLivre
};
